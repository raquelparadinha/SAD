{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get the data\n",
    "\n",
    "Para trabalhar com os dados foi necessário fazer o mapeamento dos valores de texto de 'Target' para inteiros, ficando com 'Dropout' = 0, 'Graduate' = 1 e 'Enrolled' = 2. Como os valores dos atributos são todos numéricos, não foi necessário fazer nenhum tratamento sobre os mesmos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('Dataset_Trabalho.csv', sep=';')\n",
    "\n",
    "\n",
    "print(raw_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot with the distribution of samples for each label (class)\n",
    "\n",
    "Neste passo, fizemos um gráfico no qual é possível observar a distribuição do número de amostras para cada valor de 'Target'. Com isto conseguimos verificar que o nosso dataset tem um problema de balanceamento de classes (class imbalance), ou seja, o número de amostras não é igual para todas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='dark')\n",
    "\n",
    "ax = sns.countplot(x='Target', data=raw_data)\n",
    "plt.title(f'Classes distribution')\n",
    "plt.xlabel('Classes')\n",
    "plt.show()\n",
    "\n",
    "# Extract the counts from the countplot\n",
    "x_labels = [tick.get_text() for tick in ax.get_xticklabels()]\n",
    "counts = [rect.get_height() for rect in ax.patches]\n",
    "print(\"Distribution [Dropout, Graduate, Enrolled]: \", counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Normalisation\n",
    "\n",
    "Como os atributos do dataset têm valores muito variados, aplicámos normalização dos dados, para melhorar a performance do modelo e para permitir uma melhor comparação entre os atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all the values to numeric\n",
    "# Dictionary to map string values to integers\n",
    "mapping = {'Dropout': 0, 'Graduate': 1, 'Enrolled': 2}\n",
    "\n",
    "# Substitute string values with integers\n",
    "raw_data['Target'] = raw_data['Target'].map(mapping)\n",
    "\n",
    "# copy the data\n",
    "normalized_data = raw_data.copy()\n",
    "\n",
    "# apply normalization techniques\n",
    "for column in normalized_data.columns:\n",
    "\tnormalized_data[column] = (normalized_data[column] - normalized_data[column].min()) / (normalized_data[column].max() - normalized_data[column].min())\t\n",
    "\n",
    "# view normalized data\n",
    "normalized_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlation Matrix\n",
    "\n",
    "Analisámos também a matrix de correlação dos atributos, para conseguir visualizar melhor a relação de cada um com o 'Target'. Valores mais altos entre 2 atributos indicam uma relação diretamente proporcional ente eles, enquanto valores mais baixos indicam proporcionalidade inversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = raw_data.corr()\n",
    "sns.set_theme(style='dark')\n",
    "f, ax = plt.subplots(figsize=(30, 30))\n",
    "sns.heatmap(corr, annot=True, ax=ax)\n",
    "plt.title('Correlation Matrix', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Subsets definition\n",
    "\n",
    "De seguida, separámos as variáveis (atributos) independentes (X) dos dependentes (y). \n",
    "\n",
    "Como o dataset tinha um número muito elevado de atributos (36) decidimos utilizar apenas os mais relevantes para o cálculo do objetivo. Após algumas tentativas e comparações, escolhemos usar 18 destes atributos.\n",
    "\n",
    "Depois dividimos X e y em sets de treino e teste, cada um com 80% e 20% do total de amostras, respetivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_names = raw_data.values[0, :-1]\n",
    "X = np.array(raw_data.values[:, :-1])\n",
    "X_with_col = pd.DataFrame(X, columns=columns_names)\n",
    "y = raw_data.values[:, -1]\n",
    "\n",
    "selector = SelectKBest(f_classif, k=18)\n",
    "X_new = selector.fit_transform(X_with_col, y)\n",
    "\n",
    "train_feature_indices = selector.get_support(indices=True)\n",
    "print(f\"Indices of the selected features: {train_feature_indices}\")\n",
    "\n",
    "# Normalisation\n",
    "scaler = StandardScaler()  \t\n",
    "scaler.fit(X_new) \n",
    "\n",
    "# splitting X and y into training and testing sets\n",
    "X_train, X_test,\\\n",
    "\ty_train, y_test = train_test_split(X_new, y,\n",
    "\t\t\t\t\t\t\t\t\ttest_size=0.2,\n",
    "\t\t\t\t\t\t\t\t\trandom_state=1)\n",
    "ax = sns.countplot(data=y_train)\n",
    "plt.title('Total number of samples in y_train')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Class imbalance treatment\n",
    "\n",
    "Por fim, para resolver o problema das amostras desequilibradas para cada classe, utilizámos SMOTE (Synthetic Minority Oversampling Technique), para aumentar o número de amostras das classes em minoria.\n",
    "\n",
    "Optámos por esta técnica, porque ao invés de apenas duplicar amostras já existentes até alcançar a quantidade desejada, gera novas amostras sintéticas encontrando os k-nearest neighbors mais próximos de cada amostra das classes em minoria e selecionando aleatoriamente um ou mais destes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smot = SMOTE()\n",
    "X_train, y_train = smot.fit_resample(X_train, y_train)\n",
    "# # equal sampling now (check)\n",
    "ax = sns.countplot(data=y_train)\n",
    "plt.title(f'Total number of samples in y_train after SMOTE application')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=100, class_weight='balanced', max_iter=10000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test) \n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred) \n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cnf_matrix, annot=True, fmt=\"d\", cmap=\"Reds\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)) \n",
    "\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred, average='weighted', zero_division=1)) \n",
    "\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred, average='weighted', zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to test new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input():\n",
    "    input_text = input_entry.get()\n",
    "    return input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_input():\n",
    "    input_data = get_input()\n",
    "    print(f\"\\nInput: {input_data}\")\n",
    "    columns_names = raw_data.values[0, :-1]\n",
    "    \n",
    "    X_values = np.array([input_data.split(\";\")], dtype=float)\n",
    "    X_df = pd.DataFrame(X_values, columns=columns_names)\n",
    "\n",
    "    X_selected = X_df.iloc[:, train_feature_indices]\n",
    "\n",
    "    X_normalized = scaler.transform([X_selected.values[0, :]])\n",
    "\n",
    "    result = logreg.predict(X_normalized) \n",
    "    print(f\"\\nResult: {result}\")\n",
    "    result_text = \"\" \n",
    "    if result[0] == 0.0:\n",
    "        result_text = 'Dropout'\n",
    "    elif result[0] == 1.0:\n",
    "        result_text = 'Graduate'\n",
    "    elif result[0] == 2.0:\n",
    "        result_text = 'Enrolled'\n",
    "\n",
    "    message_label.config(text=f\"Target prediction: {result_text}\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dados para teste\n",
    "\n",
    "Marital status;Application mode;Application order;Course;\"Daytime/evening attendance\t\";Previous qualification;Previous qualification (grade);Nacionality;Mother's qualification;Father's qualification;Mother's occupation;Father's occupation;Admission grade;Displaced;Educational special needs;Debtor;Tuition fees up to date;Gender;Scholarship holder;Age at enrollment;International;Curricular units 1st sem (credited);Curricular units 1st sem (enrolled);Curricular units 1st sem (evaluations);Curricular units 1st sem (approved);Curricular units 1st sem (grade);Curricular units 1st sem (without evaluations);Curricular units 2nd sem (credited);Curricular units 2nd sem (enrolled);Curricular units 2nd sem (evaluations);Curricular units 2nd sem (approved);Curricular units 2nd sem (grade);Curricular units 2nd sem (without evaluations);Unemployment rate;Inflation rate;GDP;Target\n",
    "\n",
    "1;17;5;171;1;1;122.0;1;19;12;5;9;127.3;1;0;0;1;1;0;20;0;0;0;0;0;0.0;0;0;0;0;0;0.0;0;10.8;1.4;1.74;Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Tk()\n",
    "window.title('SAD')\n",
    "window.geometry(\"500x300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_entry = Entry(window)\n",
    "input_entry.pack(anchor='center', pady=10)\n",
    "\n",
    "button = Button(window, text=\"Testar dados\", command=test_input)\n",
    "button.pack(anchor='center', pady=10)\n",
    "\n",
    "message_label = Label(window, text=\"\")\n",
    "message_label.pack(anchor='center', pady=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
